{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "182c52bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir=\"../models\"\n",
    "resume_pdf_path='./pdfs/Niranjan_Raju_Resume.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1f30eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_text=\"\"\"\n",
    "Job Title: Full Stack Developer\n",
    "\n",
    "Location: Hyderabad\n",
    "Position Type: Full-Time (Work from Office Only)\n",
    "Experience: 1 to 2  Years\n",
    "\n",
    "Role Overview:\n",
    "We are looking for a proactive and skilled Full Stack Developer with 8 to 18 months of experience to join our engineering team. This role is perfect for developers who are excited to work across the stack, contribute to building scalable systems, and experiment with AI and automation technologies.\n",
    "\n",
    "Key Responsibilities:\n",
    "\n",
    "Develop and maintain scalable web applications using React.js and Node.js\n",
    "Write clean, maintainable code with a focus on performance and security\n",
    "Support integration of Python-based AI/ML modules (bonus)\n",
    "Required Skills & Qualifications:\n",
    "\n",
    "Strong foundation in JavaScript/TypeScript for both frontend and backend\n",
    "Experience with React.js and Node.js\n",
    "Familiarity with relational and NoSQL databases (e.g., PostgreSQL, DynamoDB)\n",
    "Understanding of cloud services and serverless architecture (AWS Lambda, Kinesis)\n",
    "Basic exposure to Python for automation or ML is a plus\n",
    "A growth mindset, team player attitude, and willingness to learn new technologies\n",
    "Good to Have\n",
    "\n",
    "Exposure to CI/CD workflows\n",
    "Knowledge of RESTful API design and microservices\n",
    "Understanding of basic AI/ML concepts or pipelines\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c016670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c981840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text(pdf):\n",
    "    loader=PyPDFLoader(pdf)\n",
    "    page=loader.load()\n",
    "    return \" \".join([p.page_content for p in page])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "484418e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text=extract_pdf_text(resume_pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4a89664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed3b1782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_chunk(text):\n",
    "    splitter=RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    return splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a11df682",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_chunks=split_text_chunk(resume_text)\n",
    "jd_chunks=split_text_chunk(jd_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c091a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b87acbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_path=\"../models/BAAI_bge-base-en-v1.5/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e87c32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "54ee939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "807ea4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_vectorStore=FAISS.from_texts(resume_chunks, embeddings)\n",
    "jd_vectorStore=FAISS.from_texts(jd_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "142f41db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(query, vectorStore):\n",
    "    doc_and_score=vectorStore.similarity_search_with_score(query, k=3)\n",
    "    avg_score=sum(\n",
    "        [score for _, score in doc_and_score]\n",
    "    ) / len(doc_and_score)\n",
    "    return 1 / (1 + avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92647eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_to_resume_score=sum(\n",
    "    similarity_score(chunk, resume_vectorStore) for chunk in jd_chunks\n",
    ") / len(jd_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "686a8d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_to_jd_score = sum(\n",
    "    similarity_score(chunk, resume_vectorStore) for chunk in resume_chunks\n",
    ") / len(resume_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7c1ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score=round((jd_to_resume_score + resume_to_jd_score) / 2 * 100, 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eeada9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume Match Score: 65.22000122070312%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Resume Match Score: {final_score}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b818a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "028dee5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 grammer issues\n"
     ]
    }
   ],
   "source": [
    "tool=language_tool_python.LanguageTool('en-US')\n",
    "matches=tool.check(resume_text)\n",
    "print(f\"Found {len(matches)} grammer issues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "54474675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7a7cb495",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gen_model_path='../models/tiiuae_falcon-rw-1b/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ade82160",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    text_gen_model_path,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    text_gen_model_path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6fb4fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are an ATS (Applicant Tracking System) resume optimization expert.\n",
    "\n",
    "A user has uploaded the following resume:\n",
    "\n",
    "{resume}\n",
    "\n",
    "And the job description is:\n",
    "\n",
    "{jd}\n",
    "\n",
    "Based on a detailed comparison:\n",
    "\n",
    "- Suggest improvements to align the resume with the job description.\n",
    "- Identify missing keywords, skills, or relevant experiences.\n",
    "- Provide a resume optimization score out of 100.\n",
    "- Correct any grammar or formatting issues in the resume.\n",
    "\n",
    "Return the response in **markdown format**, organized into the following sections:\n",
    "\n",
    "### Resume Improvement Suggestions\n",
    "...\n",
    "\n",
    "### Missing Keywords or Experience\n",
    "...\n",
    "\n",
    "### Grammar and Formatting Corrections\n",
    "...\n",
    "\n",
    "### Resume Optimization Score\n",
    "...\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f2553a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "generator=pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ca98001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output=generator(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6c505b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an ATS (Applicant Tracking System) resume optimization expert.\n",
      "\n",
      "A user has uploaded the following resume:\n",
      "\n",
      "{resume}\n",
      "\n",
      "And the job description is:\n",
      "\n",
      "{jd}\n",
      "\n",
      "Based on a detailed comparison:\n",
      "\n",
      "- Suggest improvements to align the resume with the job description.\n",
      "- Identify missing keywords, skills, or relevant experiences.\n",
      "- Provide a resume optimization score out of 100.\n",
      "- Correct any grammar or formatting issues in the resume.\n",
      "\n",
      "Return the response in **markdown format**, organized into the following sections:\n",
      "\n",
      "### Resume Improvement Suggestions\n",
      "...\n",
      "\n",
      "### Missing Keywords or Experience\n",
      "...\n",
      "\n",
      "### Grammar and Formatting Corrections\n",
      "...\n",
      "\n",
      "### Resume Optimization Score\n",
      "...\n",
      "\n",
      "“I was in a position of trust, and I was not only looking at a very, very young girl, but it was a very young child.”\n",
      "The former CEO of the Federal Trade Commission, Thomas M. Miller, Jr., has been forced to resign after he was caught on video saying that he would “be happy to” have a child with a 15-year-old girl.\n",
      "Miller, who was also a former U.S. Senator, was caught on a video by the Federal Bureau of Investigation (FBI) that shows him joking about the possibility of having sex with a 15-year-old girl.\n",
      "The video was filmed by the FBI during a 2017 sting operation. He is seen saying that he was “not a bad person” and “very happy” with his “lifestyle.”\n",
      "“I was in a position of trust, and I was not only looking at a very, very young girl, but it was a very young child,” he told the agent.\n",
      "The former politician also said that he was “very happy” to “go to a younger person.”\n",
      "“I was happy to be a person that a\n"
     ]
    }
   ],
   "source": [
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee3de2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
