{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openai-community/gpt2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the model in locallt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from huggingface_hub import snapshot_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"openai-community/gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir=\"../models\"\n",
    "folder_name=model_name.replace(\"/\",\"_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dir=f'{base_dir}/{folder_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_download(\n",
    "    repo_id=\"openai-community/gpt2\",\n",
    "    local_dir=local_dir,\n",
    "    local_dir_use_symlinks=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting the downloaded model locally and using it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_model_path='../models/openai-community_gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers=GPT2Tokenizer.from_pretrained(gpt2_model_path)\n",
    "model=GPT2LMHeadModel.from_pretrained(gpt2_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text=\"Once upon a time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=tokenizers.encode(\n",
    "    input_text,\n",
    "    return_tensors='pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output=model.generate(\n",
    "#     input_ids,\n",
    "#     max_length=50,\n",
    "#     pad_token_id=tokenizers.eos_token_id,\n",
    "#     do_sample=True,\n",
    "#     top_k=50,\n",
    "#     top_p=0.95,\n",
    "#     temperature=0.7,\n",
    "#     num_return_sequences=5,\n",
    "#     no_repeat_ngram_size=2,\n",
    "#     early_stopping=True,\n",
    "#     repetition_penalty=1.2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output=model.generate(\n",
    "    input_ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time, the world was a place of great beauty and great danger. The world was a place of great'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizers.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating with LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_model_path=\"../models/openai-community_gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers=GPT2Tokenizer.from_pretrained(gpt2_model_path)\n",
    "model=GPT2LMHeadModel.from_pretrained(gpt2_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers.pad_token=tokenizers.eos_token\n",
    "model.config.pad_token_id=model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "hf_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizers,\n",
    "    return_full_text=True,\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    temperature=0.7,\n",
    "    repetition_penalty=1.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "hf_pipeline=pipeline(\n",
    "   \"text-generation\",\n",
    "   tokenizer=tokenizers,\n",
    "    model=model,\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=HuggingFacePipeline(\n",
    "    pipeline=hf_pipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Write a short and imaginative story about {topic}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chain.run(\"A dragon who learn to code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŒŸ Story:\n",
      " Write a short and imaginative story about A dragon who learn to code and become a dragon, and then the other way around.\n",
      "\n",
      "This book is a must for young readers who want a fun experience of science fiction and fantasy.\n",
      "\n",
      "In the end, this book will be a must for anyone who wants to have a chance to read it, and is a great introduction to the science fiction genre.\n",
      "\n",
      "The book's primary purpose is to introduce you to the science fiction world, and to give you a good idea of what it is like to learn about it.\n",
      "\n",
      "I will be writing a short story about a dragon who learns to code and become a dragon, and then the other way around.\n",
      "\n",
      "This book is a must for any who wants to learn about science fiction and fantasy.\n",
      "\n",
      "If you have any questions or comments, then feel free to email me at [email protected]\n",
      "\n",
      "I will be writing a short story about a dragon who learns to code and become a dragon, and then the other way around.\n",
      "\n",
      "This book is a must for any who wants to learn about science fiction and fantasy.\n",
      "\n",
      "If you have any questions or comments, then feel free to email me at [email protected]\n",
      "\n",
      "I will be writing a short story about a dragon who learns to code and become\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸŒŸ Story:\\n\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
