{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import SequentialChain, LLMChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"What is the capital of France?\",\n",
    "        \"options\": {\n",
    "            \"a\": \"Berlin\",\n",
    "            \"b\": \"Madrid\",\n",
    "            \"c\": \"Paris\",\n",
    "            \"d\": \"Rome\"\n",
    "        },\n",
    "        \"correct_option\": \"c\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\" \n",
    "text={text}\n",
    "subject={subject}\n",
    "tone={tone}\n",
    "number={number}\n",
    "\n",
    "Instructios:\n",
    "You are to generate a quiz in a {tone} tone based on the subject \"{subject}\".\n",
    "the quiz should contain {number} multiple-choice question.\n",
    "Each question should have:\n",
    "- a clear and concise question text\n",
    "- four option lebeled A, B, C, D\n",
    "- a correct answer key\n",
    "\n",
    "output must be in the following JSON format:\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"subject\", \"number\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quiz_chain = LLMChain(\n",
    "#     llm=llm,\n",
    "#     prompt=quiz_prompt,\n",
    "#     output_key=\"quiz\",\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "quiz_chain= quiz_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "You are an expert English grammarian and writer. Given a multiple-choice quiz for {subject} students,\n",
    "you need to evaluate the complexity of the questions and provide a complete analysis of the quiz.\n",
    "\n",
    "- Use **no more than 50 words** for the complexity analysis.\n",
    "- If any question does not align with the cognitive and analytical abilities of the students,\n",
    "  revise only those questions and adjust the tone to better suit the appropriate difficulty level.\n",
    "\n",
    "Quiz MCQs:\n",
    "{quiz}\n",
    "\n",
    "Please provide your evaluation and the updated quiz (if needed) from the perspective of an expert English writer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],\n",
    "    template=TEMPLATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_chain = LLMChain(\n",
    "#     llm=llm,\n",
    "#     prompt=quiz_evalution_prompt,\n",
    "#     output_key=\"review\",\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "review_chain= review_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_evaluate_chain = SequentialChain(\n",
    "#     chains=[quiz_chain, review_chain],\n",
    "#     input_variables=[\"text\", \"subject\", \"number\", \"tone\", \"response_json\"],\n",
    "#     output_variables=[\"quiz\", 'review'],\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "quiz_evaluate_chain=(\n",
    "    RunnableLambda(lambda inputs:{\n",
    "        **inputs,\n",
    "        \"quiz\": quiz_chain.invoke(inputs)\n",
    "    }) |\n",
    "    RunnableLambda(lambda inputs:{\n",
    "        \"quiz\": inputs[\"quiz\"],\n",
    "        \"review\": review_chain.invoke({\n",
    "            \"quiz\": inputs[\"quiz\"],\n",
    "            \"subject\": inputs[\"subject\"]\n",
    "        })\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "file_path = r'../data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER=5\n",
    "SUBJECT=\"Data science\"\n",
    "TONE=\"Hard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with get_openai_callback() as cb:\n",
    "#     response = gen_evaluate_chain(\n",
    "#         {\n",
    "#             \"text\":TEXT,\n",
    "#             \"number\":NUMBER,\n",
    "#             \"subject\":SUBJECT,\n",
    "#             \"tone\":TONE,\n",
    "#             \"response_json\":json.dumps(RESPONSE_JSON)\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "  response = quiz_evaluate_chain.invoke(\n",
    "       {\n",
    "        \"text\":TEXT,\n",
    "        \"subject\":SUBJECT,\n",
    "        \"number\":NUMBER,\n",
    "        \"tone\":TONE,\n",
    "        \"response_json\":json.dumps(RESPONSE_JSON)\n",
    "    }\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens used: 988\n",
      "Prompt Tokens: 603\n",
      "Completion Tokens: 385\n",
      "Total cose: $0.00032145\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tokens used: {cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "print(f\"Total cose: ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'mcq': 'What is the primary purpose of data science?',\n",
       "  'options': {'a': 'To create programming languages',\n",
       "   'b': 'To extract knowledge and insights from data',\n",
       "   'c': 'To develop hardware solutions',\n",
       "   'd': 'To manage databases'},\n",
       "  'correct_answer': 'b'},\n",
       " '2': {'mcq': 'Which of the following fields does NOT directly contribute to data science?',\n",
       "  'options': {'a': 'Statistics',\n",
       "   'b': 'Philosophy',\n",
       "   'c': 'Computer Science',\n",
       "   'd': 'Information Science'},\n",
       "  'correct_answer': 'b'},\n",
       " '3': {'mcq': 'According to Jim Gray, how is data science characterized in relation to traditional paradigms of science?',\n",
       "  'options': {'a': 'As a purely theoretical field',\n",
       "   'b': 'As the first paradigm of science',\n",
       "   'c': 'As a fourth paradigm that is data-driven',\n",
       "   'd': 'As a subset of empirical science'},\n",
       "  'correct_answer': 'c'},\n",
       " '4': {'mcq': 'Which of the following skills is essential for a data scientist?',\n",
       "  'options': {'a': 'Creative writing',\n",
       "   'b': 'Statistical knowledge',\n",
       "   'c': 'Artistic design',\n",
       "   'd': 'Mechanical engineering'},\n",
       "  'correct_answer': 'b'},\n",
       " '5': {'mcq': 'What role does human-computer interaction play in data science, according to Nathan Yau?',\n",
       "  'options': {'a': 'It is irrelevant to data analysis',\n",
       "   'b': 'It enhances user control and exploration of data',\n",
       "   'c': 'It complicates the data science process',\n",
       "   'd': 'It is only necessary in software development'},\n",
       "  'correct_answer': 'b'}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_dict= json.loads(quiz_str)\n",
    "quiz_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table = []\n",
    "for key, value in quiz_dict.items():\n",
    "    mcq = value['mcq']\n",
    "    options = \" || \".join(\n",
    "        [\n",
    "            f\"{option} : {option_value} \"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "        ]\n",
    "    )\n",
    "    correct_answer = value[\"correct_answer\"]\n",
    "    quiz_table.append({\"MCQ\":mcq, \"Choices\":options, \"Correct_Answer\":correct_answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCQ</th>\n",
       "      <th>Choices</th>\n",
       "      <th>Correct_Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the primary purpose of data science?</td>\n",
       "      <td>a : To create programming languages  || b : To...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which of the following fields does NOT directl...</td>\n",
       "      <td>a : Statistics  || b : Philosophy  || c : Comp...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to Jim Gray, how is data science cha...</td>\n",
       "      <td>a : As a purely theoretical field  || b : As t...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which of the following skills is essential for...</td>\n",
       "      <td>a : Creative writing  || b : Statistical knowl...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What role does human-computer interaction play...</td>\n",
       "      <td>a : It is irrelevant to data analysis  || b : ...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 MCQ  \\\n",
       "0       What is the primary purpose of data science?   \n",
       "1  Which of the following fields does NOT directl...   \n",
       "2  According to Jim Gray, how is data science cha...   \n",
       "3  Which of the following skills is essential for...   \n",
       "4  What role does human-computer interaction play...   \n",
       "\n",
       "                                             Choices Correct_Answer  \n",
       "0  a : To create programming languages  || b : To...              b  \n",
       "1  a : Statistics  || b : Philosophy  || c : Comp...              b  \n",
       "2  a : As a purely theoretical field  || b : As t...              c  \n",
       "3  a : Creative writing  || b : Statistical knowl...              b  \n",
       "4  a : It is irrelevant to data analysis  || b : ...              b  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(quiz_table)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data_science.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
